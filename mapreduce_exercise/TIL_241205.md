Custom Partitioner, SortComparator, GroupingComparator를 정의하고, 이를 통해 맵리듀스 이차 정렬을 구현해 보았다.

궁금하지만 아직 안 찾아본 것들
1. 기존 코드는 리듀서 잡마다 O(2n)의 시간이 필요한데, 새로 만든 코드는 소팅 작업이 들어가 있다.  
만약 기존 코드를 기반으로 리듀서 안에다 소팅 작업을 추가한 후 새 코드처럼 한 번의 iteration만 돌게 하면 O(nlogn) + O(n)의 시간이 들어서 더 손해인 것 같다.  
맵리듀스 이차 정렬은 이것보다 더 빠른 정렬을 제공하는걸까?
<br>
<br>
2. 1에서 만약 그렇지 않다면 어떤 경우에 이차정렬을 사용하는 것이 유리할까?  
어차피 정렬에 O(nlogn) 시간이 드는 것이 똑같다면 리듀서 잡 안에서 정렬하지 않고 Custom SortComparator를 이용한 이차정렬을 하는 이유가 궁금하다

---
찾아본 결과

1. 맵리듀스의 이차 정렬을 primaryKey로 O(nlogn)의 정렬을 하고, secondaryKey로 또다른 O(nlogn)의 정렬을 한다고 생각하면 안 된다.  
tuple인 (primaryKey, secondaryKey) 로 한 번에 정렬을 하기 때문에 정렬에 드는 시간은 O(nlogn) 한 번이다.  
<br>
물론 질문에서처럼 리듀서 안에다 secondaryKey 기준의 소팅을 집어넣으면 O(2n)이던 기존 코드보다 더 느려지는 게 맞지만, 핵심은 두 가지 값을 가진 복합키로 한 번만 소팅을 한 다는 점이다.


2. 이번 실습의 경우는 이차 정렬을 굳이 사용하지 않아도 성능상 문제가 없었지만, 다음과 같은 경우 이차정렬이 더 유리하다
   - 리듀서에서 정렬된 데이터를 순차적으로 처리해야 할 때
   - 리듀서가 정렬을 가정한 알고리즘을 사용할 때
   - 데이터의 정렬 상태를 유지해야 할 때
   - 리듀서가 특정 범위의 데이터를 추출해야 할 때

   <br>
   즉, 이번 실습 처럼 최솟값 또는 최댓값 하나만 찾아야 하는 경우가 아닌, 데이터 전체가 정렬을 요하는 경우들이다.
- 만약 리듀서가 여러 개인데 secondaryKey로 정렬이 안 된 상태의 데이터를 리듀서가 받아서 정렬해야 한다면, 불필요한 네트워크 전송량이 늘어나기도 한다.  
- 하둡의 설계 철학은 맵 단계에서 최대한 데이터를 처리하고 리듀스에서 단순화된 작업을 수행하는 것이므로, 리듀스에서 재정렬하는 방식은 비효율적이다.  
- (참고) 하둡의 정렬은 맵리듀스 프레임워크 자체의 TeraSort 알고리즘에 의존
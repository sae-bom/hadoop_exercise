### 2 개의 잡을 연속적으로 실행하여 Top 30 Movie Rating 구하기 실습

- 보통 여러 개의 잡을 연속적으로 실행할 때에는 워크플로 도구를 사용하지만, 이번에는 한 클래스에서 수행하기로 한다
---
이번 실습에서 TopKMapper와 TopKReducer의 동작이 같아서 (내림차순으로 정렬 순서를 바꾼 것만 빼고)  
Mapper만 작성해서 내림차순 코드를 추가하고, Reducer 구현은 생략할 수 있지 않나? 하는 의문이 있었다.  

그런데 실습에서는 input file의 크기가 작아서 Mapper task가 하나만 생겨서 그런 것이었고, 만약 Mapper task가 두 개 이상이라면 각각의 Mapper에서 top 30개를 구하고, Reducer에서는 그 중에서 또 top 30개를 구해야 한다.

이 가정이 맞는지 궁금해서 실험해보고 싶었다.  
`job2.setNumReduceTasks(1);` 처럼 MapperTasks의 갯수를 조절해보고 싶었는데,  
`Hadoop MapReduce에서 맵퍼의 개수는 기본적으로 입력 데이터의 스플릿 개수에 따라 결정됩니다. 즉, 입력 파일의 크기와 HDFS 블록 크기에 따라 자동으로 조정됩니다.` 라고 한다.  
그래서 다음과 같은 우회 방법을 사용했다.

```
long splitSize = 100 * 1024; // 100 KB
job2.getConfiguration().setLong("mapreduce.input.fileinputformat.split.maxsize", splitSize);
job2.getConfiguration().setLong("mapreduce.input.fileinputformat.split.minsize", splitSize);
```
3개의 Mapper Task가 생겼고, 예상대로 Reducer task가 따로 없다면 30개가 아닌 90개의 영화 리스트가 최종 결과로 출력되는 것을 확인하였다. 